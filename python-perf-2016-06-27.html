<!doctype html>
<html lang="en">

	<head>
		<meta charset="utf-8">

		<title>Pythran - C++ for Snakes</title>
        <link rel="stylesheet" href="css/reveal.css">
        <link rel="stylesheet" href="css/theme/serif.css" id="theme">

        <!-- Code syntax highlighting -->
        <link rel="stylesheet" href="lib/css/zenburn.css">

        <!-- Printing and PDF exports -->
        <script>
            var link = document.createElement( 'link' );
            link.rel = 'stylesheet';
            link.type = 'text/css';
            link.href = window.location.search.match( /print-pdf/gi ) ? 'css/print/pdf.css' : 'css/print/paper.css';
            document.getElementsByTagName( 'head' )[0].appendChild( link );
        </script>

        <!--[if lt IE 9]>
        <script src="lib/js/html5shiv.js"></script>
        <![endif]-->

	</head>

	<body>

		<div class="reveal">


			<!-- Any section element inside of this container is displayed as a slide -->
			<div class="slides">

       <section>

				<section>
                    <h2>Python: When Performance Matters</h2>
					<p>
                    <small>Proudly made in <em>Namek</em> by <a href="http://serge.liyun.free.fr/serge/">serge-sans-paille</a> &amp; <a  href="http://fr.viadeo.com/fr/profile/pierrick.brunet">pbrunet</a></small>
					</p>
				</section>

				<section>
                <h2><code class="bash">/me</code></h2>
                <h3>Serge « sans paille » Guelton</h3>
                <p>
                <pre><code class="bash">$ whoami
sguelton</code></pre>
                <ul>
                    <li>R&amp;D engineer at <a href="http://www.quarkslab.com/">QuarksLab</a> on compilation for security</li>
                    <li>Associate researcher at Télécom Bretagne</li>
                </ul>
                </p>
				</section>
                <section>
                    <h2>Myth: Python is slow</h2>
                    <h3><a href="http://benchmarksgame.alioth.debian.org/">The Computer Language Benchmarks Game</a></h3>
                    <p>
                    <pre>
binary-trees
	
source 	    secs 
Python 3    152.06
C++ g++  	6.98
</pre>
                </section>

                <section>
                    <h2>Reality: CPython is fast (enough) in some cases</h2>
                    <p>
                    On the <code>pidigits</code> benchmark, that uses BigInts
                    <pre>
× 	source 	secs
1.0 Pascal  1.73
1.0 C gcc	1.73
1.0 Rust	1.74
1.1 Fortran	1.92
1.3 Python3	2.20
1.3 C++ g++	2.29

                    </pre>
                    </p>
                </section>

                <section>
                    <h2>Reality: CPython is really slow for numeric computations</h2>
                    <p>
                    On the <code>spectral-norm</code> benchmark, that uses list and scalars
                    <pre>
×   source    secs
1.0 C gcc     1.98
2.1 Java      4.26
8.0 Node.js  15.77
126 Python3 250.12
                    </pre>
                    </p>
                </section>

                <section>
                    <h2>But that's not a property of Python!</h2>
                    <p>
                    <pre><code class="shell">$ gcc sn.c -o sn -O3
$ time ./sn 5500
./sn 5500  4.86s user 0.00s system 99% cpu 4.864 total
$ pythran sn.py
$ python -m timeit 'import sn' 'sn.main(5500)'
10 loops, best of 3: 4.79 sec per loop</code></pre>
                    </p>

                </section>

        </section>

        <section>

            <section>
                <h2>Tell me Why!</h2>
                <h3>Interpreted code</h3>
                <pre><code class="python">
>>> import dis
>>> code = lambda x, y: x + y
>>> dis.dis(code)
  1           0 LOAD_FAST                0 (x)
              3 LOAD_FAST                1 (y)
              6 BINARY_ADD          
              7 RETURN_VALUE</code></pre>

                VS.
                <pre><code class="asm">
foo:
    leal    (%rdi,%rsi), %eax
    ret</code></pre>
            </section>

            <section>
                <h2>Tell me Why!</h2>
                <h3>Indirections Everywhere</h3>
                <p>
                <ul>
                    <li><code>LOAD_FAST</code> &rArr; array lookup</li>
                    <li><code>BINARY_ADD</code> &rArr; dict lookup</li>
                </ul>
                </p>
                <h3>Funcion Call Overhead</h3>
                <ol>
                    <li>Suspend current frame</li>
                    <li>Create a new frame</li>
                    <li>Push it on the stack</li>
                </ol>
                <p>
                </p>
            </section>

            <section>
                <h2>Tell me Why!</h2>
                <h3>No optimization</h3>
                (except somme peephole optimization on the bytecode)
                <pre><code class="shell">$ gcc sn.c -o sn -O0 -fsanitize=address -fsanitize=null -fsanitize=signed-integer-overflow -fsanitize=integer-divide-by-zero
$ time ./sn 5500
./a.out 5500  11.04s user 0.02s system 99% cpu 11.053 total
                </code></pre>
            </section>

            <section>
                <h2>Tell me Why!</h2>
                <h3>Poor Parallelism Support</h3>
                Global Interpreter Lock &rArr; few parallism gain (except io/native calls)

                Do not speak about vectorization
            </section>

            <section>
                <h2>Prove me wrong</h2>
                <p>
                <ul>
                    <li>Efficient dictionnary</li>
                    <li>Cached String hashing</li>
                    <li>BigInt comparable to GMP</li>
                </ul>
                </p>
                <p>
                <strong>Many Native Library Wrappers</strong>
                </p>
            </section>


        </section>
        <section>

            <section>
                <h2>Then comes NumPy</h2>
                <p>
                A Python packages for numeric computations
                <ul>
                    <li>Flat Data Types optimized for Native &harr; Python transfer</li>
                    <li>Lightweight BLAS wrappers</li>
                    <li>All math routines and operators</li>
                    <li>Many libraries (random, polynomial, linalg, fft)</li>
                    <li>Relatively extensible (aggregate, ufunc, f2py)</li>
                </ul>
                </p>
                <p>
                &rarr; Keystone of the Python scientific ecosystem!
                </p>
            </section>

            <section>
                <h2>Example of (bad) Python code</h2>
                <pre><code class="python">def pairwise(X):
    M, N = X.shape
    D = np.empty((M, M), dtype=np.float64)
    for i in range(M):
        for j in range(M):
            d = 0.0
            for k in range(N):
                tmp = X[i, k] - X[j, k]
                d += tmp * tmp
            D[i, j] = sqrt(d)
    return D</code></pre>
            </section>
            <section>
                <h2>Do it the NumPy way!</h2>
                <pre><code class="python">import numpy as np
def pairwise(X):
    return np.sqrt(((X[:, None, :] - X) ** 2).sum(-1))</code></pre>
            </section>

            <section>
                <h2>Numpy Ecosystem</h2>
                <p>
                <ul>
                    <li><strong>plot:</strong> Matplotlib</li>
                    <li><strong>Image/Signal:</strong> Scipy</li>
                    <li><strong>Stats:</strong> Scipy</li>
                    <li><strong>Machine learning:</strong> SKlearn</li>
                </ul>
                </p>
            </section>

            <section>
                <h2>Performance Tips</h2>
                <p>
                <ol>
                    <li>You don't need performance Tips, you're a scientist, get the job done!</li>
                    <li>Benchmark! Profile!</li>
                    <ul>
                        <li>Use mpi4py for cluster parallelization</li>
                        <li>Use Cython/Hope/Parakeet/Pythran/Numba for more raw perf</li>
                        <li>Use multithreading from Cython/Pythran</li>
                        <li>Use GPUs with PyCUDA/PyOpenCL/GT-Py</li>
                    </ul>
                    <li><strong>Don't</strong> use explicit indexing/looping</li>
                </ol>
                </p>
            </section>

            <section>
                <h2>Example of MPI interaction</h2>
                <p>
                <pre><code class="python">from mpi4py import MPI
import numpy as np

comm = MPI.COMM_WORLD
rank = comm.Get_rank()

if rank == 0:
    data = np.arange(100, dtype='i')
else:
    data = np.empty(100, dtype='i')
comm.Bcast(data, root=0)</code></pre>
                </p>
            </section>
        </section>

        <section>

            <section>
                <h2>Calling Native Code from Python</h2>
                <h3><code>ctypes</code></h3>
                    <pre><code class="python">>>> from ctypes import *
>>> libm = cdll.LoadLibrary('libm.so.6')
>>> sqrt = libm.sqrt
>>> sqrt.argtypes, sqrt.restype = (c_double,), c_double
>>> sqrt(4.)</code></pre>
            </section>

            <section>
                <h2>Building and Calling Native Code from Python</h2>
                <h3><code>cffi</code></h3>
                <pre><code class="python">>>> from cffi import FFI
>>> ffi = FFI()
>>> ffi.cdef('int add(int, int);')
>>> C = ffi.verify('int add(int x, int y) { return x+y;}')
>>> C.add(40, 2)
42</code></pre>
            </section>

            <section>
                <h2>Building Native Modules</h2>
                <h3><code>Cython</code></h3>
                <pre><code class="python">cimport cython
cpdef double add(double x, double y):
    return x + y</code></pre>

                Then
                <pre><code class="shell">$ cython -a add.pyx
$ gcc `python-config --cflags --ldflags` -fPIC -shared add.c -o add.so</code></pre>
            </section>
            <section>
                <h2>Building Native Modules</h2>
                <h3><code>Pythran</code></h3>
                <pre><code class="python">#pythran export add(double, double)
def add(x, y):
    return x + y</code></pre>

                Then
                <pre><code class="shell">$ pythran add.py</code></pre>
            </section>

            <section>
                <h2>Wrapping Native Code</h2>
                <h3>SWIG</h3>
                <p>Through a custom compiler + interface file</p>
                <h3>Boost.Python</h3>
                <p>Regular C++ code + runtime deps</p>
                <h3>pybind11</h3>
                <p>Regular C++ code + modern compiler</p>
            </section>

            <section>
                <h2>PyBind11 example</h2>
                <pre><code class="c++">
#include <pybind11/pybind11.h>
int add(int i, int j) {
    return i + j;
}
namespace py = pybind11;
PYBIND11_PLUGIN(example) {
    py::module m("example", "pybind11 example plugin");
    m.def("add", &add, "A function which adds two numbers");
    return m.ptr();
}</code></pre>
            </section>

            <section>
                <h2>General Considerations</h2>
                <p>
                Pro:
                <ul>
                    <li>Leverage existing libs</li>
                    <li>Parallelism</li>
                    <li>Vectorization (SIMD code)</li>
                </ul>
                </p>
                <p>
                Cons:
                <ul>
                    <li>Type conversion cost</li>
                    <li>Packaging issues</li>
                    <li>Runtime dependencies</li>
                    <li>Exceptions / Error handling</li>
                </ul>
                </p>
            </section>

        </section>

        <section>
            <section>
                <h2>Just in Time Compilation</h2>
                <h3><code>PyPy</code></h3>
                <em>a full interpreter</em>
                <p>
                <ul>
                    <li>Python2 and Python3</li>
                    <li>Partial Numpy Support</li>
                    <li><code>cffi</code> compatibility</li>
                </ul>
                </p>
                <p>
                <strong>Promise:</strong> no code change
                </p>
            </section>

            <section>
                <h2>Just in Time Compilation</h2>
                <h3><code>Numba</code></h3>
                <em>Based on LLVM</em>
                <pre><code>from numba import jit
@jit
def add(x, y): return x + y</pre></code>
                <h3><code>Hope</code></h3>
                <em>Based on C++</em>
                <pre><code>from hope import jit
@jit
def add(x, y): return x + y</pre></code>
            </section>
        </section>



        <section>

            <section>
                <h2>Profiling Interpreted Code</h2>
                <h3><code>cProf</code></h3>
                <p>
                <pre><code class="shell">$ python -m cProfile -s cumtime myscript.py
                </code></pre>
                </p>
                <h3><code>timeit</code></h3>
                <p>
                <pre><code class="shell">$ python -m timeit -s 'import mymodule' 'mymodule.run(2)'
                </code></pre>
                </p>
            </section>

            <section>
                <h2>Profiling native Code</h2>
                <em>Usual suspects</em>
                <h3><code>perf</code></h3>
                <p>
                <pre><code class="shell">$ perf run python myscript.py
$ perf report
                </code></pre>
                </p>
                <h3><code>valgrind</code></h3>
                <p>
                <pre><code class="shell">$ valgrind --tool=callgrind python myscript.py
$ kcachegrind callgrind.out.1982
                </code></pre>
                </p>
            </section>

        </section>

				<section>
					<h1>THE END</h1>
                    <em>Some reading</em>
                    <p>
                    <ul>
                        <li><a href="https://wiki.python.org/moin/PythonSpeed/">https://wiki.python.org/moin/PythonSpeed</a></li>
                        <li>High Performance Python, Practical Performant Programming for Humans by Micha Gorelick, Ian Ozsvald</li>
                    </ul>
                    </p>

				</section>

			</div>

		</div>

		<script src="lib/js/head.min.js"></script>
		<script src="js/reveal.js"></script>

		<script>

			// Full list of configuration options available at:
			// https://github.com/hakimel/reveal.js#configuration
			Reveal.initialize({
				controls: true,
				progress: true,
				history: true,
				center: true,

				transition: 'slide', // none/fade/slide/convex/concave/zoom

				// Optional reveal.js plugins
				dependencies: [
					{ src: 'lib/js/classList.js', condition: function() { return !document.body.classList; } },
					{ src: 'plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
					{ src: 'plugin/highlight/highlight.js', async: true, condition: function() { return !!document.querySelector( 'pre code' ); }, callback: function() { hljs.initHighlightingOnLoad(); } },
					{ src: 'plugin/zoom-js/zoom.js', async: true },
					{ src: 'plugin/notes/notes.js', async: true }
				]
			});

		</script>

	</body>
</html>
